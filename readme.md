# 游댌 Bot de Resoluciones  

Este proyecto implementa un **chatbot para consultar resoluciones en documentos PDF y Word**, utilizando **LangChain**, **FAISS**, **Ollama** y **Streamlit**.  
El sistema permite hacer preguntas en espa침ol y recibir respuestas con **citas exactas al archivo y n칰mero de resoluci칩n correspondiente**.  

---

## 游 Requisitos previos  

Antes de ejecutar el chatbot, aseg칰rate de contar con lo siguiente:  

- **Python 3.10+** instalado  
- **pip** para gestionar dependencias  
- **Ollama** instalado en tu m치quina ([descargar desde la web oficial](https://ollama.com))  
- Al menos **40GB de espacio libre en disco** (para descargar y manejar modelos de lenguaje grandes)  
- Memoria RAM recomendada: **16GB+**  

丘멆잺 **Nota:** El rendimiento depender치 del hardware. En equipos con menos memoria puede que la descarga de modelos falle o el chatbot no funcione correctamente.  

---

## 游닍 Instalaci칩n  

### 1. Clona este repositorio  

```bash
git clone https://github.com/tu-usuario/bot-resoluciones.git
cd bot-resoluciones
## 游닍 Instalaci칩n

### 2. Instala dependencias

El proyecto incluye un archivo `setup_and_run.py` que instala autom치ticamente los paquetes de `requirements.txt` y lanza la aplicaci칩n:

```bash
python setup_and_run.py


### 3. Configura Ollama y el modelo

Antes de ejecutar el chatbot, necesitas descargar el modelo de lenguaje `gemma3:12b` en Ollama:

```bash
ollama pull gemma3:12b


# 游닇 Nota importante sobre Ollama

Al ejecutar el comando para descargar el modelo `gemma3:12b` en Ollama, puede ocurrir:

- Que Ollama descargue el modelo directamente desde consola.  
- Que Ollama abra la aplicaci칩n gr치fica. En ese caso:
  1. Selecciona el modelo de lenguaje en la interfaz.  
  2. Haz una consulta sencilla y presiona Enter.  
  3. Espera a que termine la descarga.  
  4. Cierra la aplicaci칩n y det칠n el comando en consola.  

Despu칠s de este paso, Ollama ya tendr치 el modelo disponible localmente.

---

## 郊윒잺 Ejecuci칩n

Si ya se configur Ollama y las dependencias, simplemente corre el proyecto:

```bash
python setup_and_run.py

Esto iniciar치 **Streamlit** y podr치s acceder al chatbot en tu navegador en la direcci칩n:

http://localhost:8501

